{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains functions for loading the metric logs and printing them in nice format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "import warnings\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_metric(filepath, start_step=0):\n",
    "    \"\"\"Load a metric file and return a dictionary containing metric arrays.\"\"\"\n",
    "    data = np.load(filepath)\n",
    "    return (data[()]['score_matrix_mean'], data[()]['score_pair_matrix_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "track_names = ('Drums', 'Piano', 'Guitar', 'Bass', 'Ensemble', 'Reed',\n",
    "               'Synth Lead', 'Synth Pad')\n",
    "metric_names = ('empty bar rate', '# of pitch used', 'qualified note rate',\n",
    "                'polyphonicity', 'note in scale', 'drum in pattern rate',\n",
    "                '# of chroma used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traing_data_eval_path = './data/training_data/lastfm_alternative_8b_phrase.npy'\n",
    "data_dir = './data/eval_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = [\n",
    "    ('pretrained (BS)', \"lastfm_alternative_pretrain_g_proposed_d_proposed_\"\n",
    "                        \"test_time_bernoulli.npy\"),\n",
    "    ('pretrained (HT)', \"lastfm_alternative_pretrain_g_proposed_d_proposed_\"\n",
    "                        \"test_time_round.npy\"),\n",
    "    ('proposed (+SBNs)', \"lastfm_alternative_train_g_proposed_d_proposed_r_\"\n",
    "                         \"proposed_bernoulli.npy\"),\n",
    "    ('proposed (+DBNs)', \"lastfm_alternative_train_g_proposed_d_proposed_r_\"\n",
    "                         \"proposed_round.npy\"),\n",
    "    ('joint (+SBNs)', \"lastfm_alternative_train_joint_g_proposed_d_proposed_r_\"\n",
    "                      \"proposed_bernoulli.npy\"),\n",
    "    ('joint (+DBNs)', \"lastfm_alternative_train_joint_g_proposed_d_proposed_r_\"\n",
    "                      \"proposed_round.npy\"),\n",
    "    ('end2end (+SBNs)', \"lastfm_alternative_end2end_g_proposed_small_d_\"\n",
    "                        \"proposed_r_proposed_bernoulli.npy\"),\n",
    "    ('end2end (+DBNs)', \"lastfm_alternative_end2end_g_proposed_small_d_\"\n",
    "                        \"proposed_r_proposed_round.npy\"),\n",
    "    ('ablated (BS)', \"lastfm_alternative_pretrain_g_proposed_d_ablated_test_\"\n",
    "                     \"time_bernoulli.npy\"),\n",
    "    ('ablated (HT)', \"lastfm_alternative_pretrain_g_proposed_d_ablated_test_\"\n",
    "                     \"time_round.npy\"),\n",
    "    ('baseline (BS)', \"lastfm_alternative_pretrain_g_proposed_d_baseline_test_\"\n",
    "                      \"time_bernoulli.npy\"),\n",
    "    ('baseline (HT)', \"lastfm_alternative_pretrain_g_proposed_d_baseline_test_\"\n",
    "                      \"time_round.npy\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_list = [('training data', load_metric(traing_data_eval_path))]\n",
    "for filename in filenames:\n",
    "    score_list.append((filename[0],\n",
    "                       load_metric(os.path.join(data_dir, filename[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_metric_table(m):\n",
    "    print('='*30 + \"\\n{:=^30}\\n\".format(' ' + metric_names[m] + ' ') + '='*30)\n",
    "    for entry in score_list:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            mean = np.nanmean(entry[1][0][m, :])\n",
    "        print(\"{:24} {:5.2f}\".format(entry[0], mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intratrack Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "======= empty bar rate =======\n",
      "==============================\n",
      "training data             0.57\n",
      "pretrained (BS)           0.53\n",
      "pretrained (HT)           0.53\n",
      "proposed (+SBNs)          0.32\n",
      "proposed (+DBNs)          0.62\n",
      "joint (+SBNs)             0.02\n",
      "joint (+DBNs)             0.26\n",
      "end2end (+SBNs)           0.49\n",
      "end2end (+DBNs)           0.51\n",
      "ablated (BS)              0.51\n",
      "ablated (HT)              0.51\n",
      "baseline (BS)             0.33\n",
      "baseline (HT)             0.33\n",
      "==============================\n",
      "====== # of pitch used =======\n",
      "==============================\n",
      "training data             4.66\n",
      "pretrained (BS)           3.52\n",
      "pretrained (HT)           3.45\n",
      "proposed (+SBNs)         14.75\n",
      "proposed (+DBNs)          9.73\n",
      "joint (+SBNs)            15.60\n",
      "joint (+DBNs)             7.56\n",
      "end2end (+SBNs)           5.21\n",
      "end2end (+DBNs)           5.93\n",
      "ablated (BS)              3.13\n",
      "ablated (HT)              3.10\n",
      "baseline (BS)             3.92\n",
      "baseline (HT)             3.73\n",
      "==============================\n",
      "==== qualified note rate =====\n",
      "==============================\n",
      "training data             0.88\n",
      "pretrained (BS)           0.67\n",
      "pretrained (HT)           0.72\n",
      "proposed (+SBNs)          0.42\n",
      "proposed (+DBNs)          0.78\n",
      "joint (+SBNs)             0.18\n",
      "joint (+DBNs)             0.55\n",
      "end2end (+SBNs)           0.67\n",
      "end2end (+DBNs)           0.28\n",
      "ablated (BS)              0.61\n",
      "ablated (HT)              0.64\n",
      "baseline (BS)             0.35\n",
      "baseline (HT)             0.37\n",
      "==============================\n",
      "======= polyphonicity ========\n",
      "==============================\n",
      "training data             0.45\n",
      "pretrained (BS)           0.20\n",
      "pretrained (HT)           0.22\n",
      "proposed (+SBNs)          0.26\n",
      "proposed (+DBNs)          0.45\n",
      "joint (+SBNs)             0.19\n",
      "joint (+DBNs)             0.19\n",
      "end2end (+SBNs)           0.16\n",
      "end2end (+DBNs)           0.29\n",
      "ablated (BS)              0.19\n",
      "ablated (HT)              0.20\n",
      "baseline (BS)             0.14\n",
      "baseline (HT)             0.14\n",
      "==============================\n",
      "======= note in scale ========\n",
      "==============================\n",
      "training data             0.59\n",
      "pretrained (BS)           0.65\n",
      "pretrained (HT)           0.65\n",
      "proposed (+SBNs)          0.68\n",
      "proposed (+DBNs)          0.68\n",
      "joint (+SBNs)             0.59\n",
      "joint (+DBNs)             0.74\n",
      "end2end (+SBNs)           0.58\n",
      "end2end (+DBNs)           0.72\n",
      "ablated (BS)              0.59\n",
      "ablated (HT)              0.59\n",
      "baseline (BS)             0.65\n",
      "baseline (HT)             0.64\n",
      "==============================\n",
      "==== drum in pattern rate ====\n",
      "==============================\n",
      "training data             0.92\n",
      "pretrained (BS)           0.75\n",
      "pretrained (HT)           0.75\n",
      "proposed (+SBNs)          0.74\n",
      "proposed (+DBNs)          0.81\n",
      "joint (+SBNs)             0.64\n",
      "joint (+DBNs)             0.74\n",
      "end2end (+SBNs)           0.71\n",
      "end2end (+DBNs)           0.85\n",
      "ablated (BS)              0.85\n",
      "ablated (HT)              0.85\n",
      "baseline (BS)             1.00\n",
      "baseline (HT)             1.00\n",
      "==============================\n",
      "====== # of chroma used ======\n",
      "==============================\n",
      "training data             2.60\n",
      "pretrained (BS)           2.11\n",
      "pretrained (HT)           2.10\n",
      "proposed (+SBNs)          6.02\n",
      "proposed (+DBNs)          4.15\n",
      "joint (+SBNs)             7.15\n",
      "joint (+DBNs)             3.68\n",
      "end2end (+SBNs)           2.60\n",
      "end2end (+DBNs)           3.16\n",
      "ablated (BS)              2.04\n",
      "ablated (HT)              2.03\n",
      "baseline (BS)             2.70\n",
      "baseline (HT)             2.63\n"
     ]
    }
   ],
   "source": [
    "for m in range(7):\n",
    "    print_metric_table(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intertrack Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "======= tonal distance =======\n",
      "==============================\n",
      "training data             0.96\n",
      "pretrained (BS)           0.98\n",
      "pretrained (HT)           1.00\n",
      "proposed (+SBNs)          0.99\n",
      "proposed (+DBNs)          0.87\n",
      "joint (+SBNs)             0.95\n",
      "joint (+DBNs)             1.03\n",
      "end2end (+SBNs)           1.41\n",
      "end2end (+DBNs)           1.10\n",
      "ablated (BS)              1.00\n",
      "ablated (HT)              1.01\n",
      "baseline (BS)             1.33\n",
      "baseline (HT)             1.35\n"
     ]
    }
   ],
   "source": [
    "print('='*30 + \"\\n{:=^30}\\n\".format(' tonal distance ') + '='*30)\n",
    "for entry in score_list:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        mean = np.nanmean(entry[1][1])\n",
    "    print(\"{:24} {:5.2f}\".format(entry[0], mean))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
