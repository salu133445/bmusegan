BinaryMuseGAN
=============

[BinaryMuseGAN](https://salu133445.github.io/bmusegan/) is a follow-up project
of the [MuseGAN](https://salu133445.github.io/musegan/) project. In this
project, we first investigate how the real-valued piano-rolls generated by the
generator may lead to difficulties in training the discriminator for CNN-based
models. To overcome the binarization issue, we propose to append to the
generator an additional refiner network, which try to refine the real-valued
predictions generated by the pretrained generator to binary-valued ones. The
proposed model is able to directly generate binary-valued piano-rolls at test
time.

We trained the network with training data collected from
[Lakh Pianoroll Dataset](https://salu133445.github.io/lakh-pianoroll-dataset/).
We used the model to generate four-bar musical phrases consisting of eight
tracks: _Drums_, _Piano_, _Guitar_, _Bass_, _Ensemble_, _Reed_, _Synth Lead_ and
_Synth Pad_. Audio samples are available
[here](https://salu133445.github.io/bmusegan/results).

Run the code
------------

### Configuration

Modify `config.py` for configuration.

- Quick setup

  Change the values in the dictionary `SETUP` for a quick setup. Documentation
  is provided right after each key.

- More configuration options

  Four dictionaries `EXP_CONFIG`, `DATA_CONFIG`, `MODEL_CONFIG` and
  `TRAIN_CONFIG` define experiment-, data-, model- and training-related
  configuration variables, respectively.

  > The automatically-determined experiment name is based only on the values
defined in the dictionary `SETUP`, so remember to provide the experiment name
manually (so that you won't overwrite a trained model).

### Run

```sh
python main.py
```

Training data
-------------

- Prepare your own data

  The array will be reshaped to (-1, `num_bar`, `num_timestep`, `num_pitch`,
  `num_track`). These variables are defined in `config.py`.

- Download our training data with this [script](training_data/download.sh) or
  download it manually [here](https://salu133445.github.io/bmusegan/data).

Citing
------

Please cite the following paper if you use the code provided in this repository.

Hao-Wen Dong and Yi-Hsuan Yang, "Convolutional Generative Adversarial Networks with Binary Neurons for Polyphonic Music Generation," _Proceedings of the 19th International Society for Music Information Retrieval Conference (ISMIR)_, 2018.<br>
[[homepage](https://salu133445.github.io/bmusegan)]
[[video](https://youtu.be/r9C2Q2oR9Ik)]
[[paper](https://salu133445.github.io/bmusegan/pdf/bmusegan-ismir2018-paper.pdf)]
[[slides](https://salu133445.github.io/bmusegan/pdf/bmusegan-ismir2018-slides.pdf)]
[[slides (long)](https://salu133445.github.io/bmusegan/pdf/bmusegan-tmac2018-slides.pdf)]
[[poster](https://salu133445.github.io/bmusegan/pdf/bmusegan-ismir2018-poster.pdf)]
[[arXiv](https://arxiv.org/abs/1804.09399)]
[[code](https://github.com/salu133445/bmusegan)]
